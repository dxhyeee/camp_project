from mpi4py import MPI
import pandas as pd
import numpy as np
import re

comm = MPI.COMM_WORLD
rank, size = comm.Get_rank(), comm.Get_size()

# Ï†ÑÎûµ Î≥ÄÍ≤Ω: Ï†ÑÏ≤òÎ¶¨ ÏàòÏ§ÄÏùÄ Í≥†Ï†ïÌïòÎêò, 'Í≥µÎ∂ÄÌïòÎäî Îç∞Ïù¥ÌÑ∞ Ïñë'ÏùÑ ÎäòÎ¶º
# ÌïôÏäµ Îã®Í≥Ñ: [Ï°∞Í∏à Í≥µÎ∂Ä, Ï†ÅÎãπÌûà Í≥µÎ∂Ä, ÎßéÏù¥ Í≥µÎ∂Ä]
learning_phases = [50, 200, 900] 

def get_clean_set(text):
    # Í∏∞Î≥∏Ï†ÅÏù∏ Ï†ÑÏ≤òÎ¶¨ Ï†ÅÏö©
    stops = ['ÏùÄ', 'Îäî', 'Ïù¥', 'Í∞Ä', 'ÏùÑ', 'Î•º', 'Ïùò', 'Ïóê', 'ÏóêÏÑú', 'ÌîºÍ≥†Ïù∏', 'ÏÇ¨Í±¥', 'ÌåêÍ≤∞']
    text = re.sub(r'[^\w\s]', '', text)
    return set([w for w in text.split() if w not in stops and len(w) > 1])

# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú
if rank == 0:
    try:
        df = pd.read_csv('legal_data_total.csv')
        full_train_data = df.iloc[:900].to_dict('records')   
        test_data = df.iloc[900:1200].to_dict('records') 
        challenge_data = df.iloc[1200:1600].to_dict('records')
    except:
        print("CSV ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§. generate_all_data.pyÎ•º Î®ºÏ†Ä Ïã§ÌñâÌïòÏÑ∏Ïöî.")
        comm.Abort()
else:
    full_train_data = test_data = challenge_data = None

# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Îäî ÎØ∏Î¶¨ Î∂ÑÏÇ∞
if rank == 0:
    test_chunks = np.array_split(test_data, size)
else:
    test_chunks = None
    
my_test_chunk = comm.scatter(test_chunks, root=0)

# 2. Îã®Í≥ÑÎ≥Ñ ÌïôÏäµ (Îç∞Ïù¥ÌÑ∞ Ïñë Ï¶ùÍ∞Ä)
for i, data_count in enumerate(learning_phases):
    # Rank 0Ïù¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÏñëÏùÑ Ï°∞Ï†àÌï¥ÏÑú ÎøåÎ¶º
    if rank == 0:
        current_train_data = full_train_data[:data_count]
    else:
        current_train_data = None
    
    # Î™®Îì† ÏΩîÏñ¥Í∞Ä ÌòÑÏû¨ Îã®Í≥ÑÏùò ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î•º Í≥µÏú†Î∞õÏùå
    current_train_data = comm.bcast(current_train_data, root=0)
    
    correct = 0
    for test_case in my_test_chunk:
        test_vec = get_clean_set(test_case['Facts'])
        best_cat, max_sim = "", -1
        
        # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏôÄ ÎπÑÍµê
        for train_case in current_train_data:
            train_vec = get_clean_set(train_case['Facts'])
            # Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
            if not (test_vec | train_vec): sim = 0
            else: sim = len(test_vec & train_vec) / len(test_vec | train_vec)
            
            if sim > max_sim: max_sim, best_cat = sim, train_case['Category']
        
        if best_cat == test_case['Category']: correct += 1
    
    # Í≤∞Í≥º ÏßëÍ≥Ñ
    total_correct = comm.reduce(correct, op=MPI.SUM, root=0)
    
    if rank == 0:
        acc = total_correct / 300 # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ 300Í∞ú Í∏∞Ï§Ä
        print(f"üîÑ Learning Phase {i+1} (Data: {data_count}ea) | Loss: {1-acc:.4f} | Accuracy: {acc*100:.2f}%")

# 3. ÏµúÏ¢Ö Ï±åÎ¶∞ÏßÄ ÌÖåÏä§Ìä∏
if rank == 0: 
    print("\nüèÅ [ÏµúÏ¢Ö Ï±åÎ¶∞ÏßÄ ÌÖåÏä§Ìä∏ (400Í∞ú)]")
    chal_chunks = np.array_split(challenge_data, size)
else:
    chal_chunks = None

my_chal_chunk = comm.scatter(chal_chunks, root=0)
current_train_data = comm.bcast(full_train_data, root=0) # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Í≤ÄÏ¶ù

final_correct = 0
for test_case in my_chal_chunk:
    test_vec = get_clean_set(test_case['Facts'])
    best_cat, max_sim = "", -1
    for train_case in current_train_data:
        train_vec = get_clean_set(train_case['Facts'])
        if not (test_vec | train_vec): sim = 0
        else: sim = len(test_vec & train_vec) / len(test_vec | train_vec)
        if sim > max_sim: max_sim, best_cat = sim, train_case['Category']
    if best_cat == test_case['Category']: final_correct += 1

total_final = comm.reduce(final_correct, op=MPI.SUM, root=0)

if rank == 0:
    final_acc = total_final / 400
    print(f"üèÜ Final Challenge Result | Loss: {1-final_acc:.4f} | Accuracy: {final_acc*100:.2f}%")
